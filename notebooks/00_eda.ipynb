{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6bbc827",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "Explore and analyze data from challenge. Main takeaways from this initial exploration.\n",
    "- Training data and test data contain an ID column and a comment_text column.\n",
    "- Labels to use on training data are six: `['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']`\n",
    "- There are no Null values on label columns\n",
    "- All the labels are classified as bools [0,1], but the columns are saved as int64\n",
    "- Most of the comments are in English (+97%). After some manual exploration, non-english cases seem to be mostly noise (short comments with names/slang on other languages). Thus, we could drop these cases to avoid some noise on our training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae7da47",
   "metadata": {},
   "source": [
    "# 1. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2845d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')  # So Python can find config.py\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import RAW_DATA_DIR, LABELS\n",
    "from utils import detect_language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d929d201",
   "metadata": {},
   "source": [
    "# 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675a5001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable tqdm for pandas apply\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9251d219",
   "metadata": {},
   "source": [
    "# 3. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(RAW_DATA_DIR / 'train.csv')\n",
    "df_test = pd.read_csv(RAW_DATA_DIR / 'test.csv')\n",
    "\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738d6b8a",
   "metadata": {},
   "source": [
    "# 3. Analyze data distribution\n",
    "Some questions to answer:\n",
    "- Are there cases with missing data?\n",
    "    > No, there are no missing data on `train` or `test` datasets\n",
    "- Are all the categories classified as bools?\n",
    "    > Yes, all the cases are classified as [0,1], but they are int64 instead of bools\n",
    "- Are all the comments in English?\n",
    "    > No, but most common language is English. Top-3 categories are: English (97.27%), German (0.36%) and French (0.23%). After some little mannual exploration of cases classified as non-English, it looks like they are mostly noise. We can drop them durint model training\n",
    "    > Test presents results similar to train, with a higher amount of noise than the latter as English comments are 93% (vs +97%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f95068",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Are there cases with missing data? ###\n",
    "missing_train = df_train.isnull().sum()\n",
    "missing_test = df_test.isnull().sum()\n",
    "\n",
    "print(\"Missing values in train dataset:\")\n",
    "print(missing_train[missing_train > 0])\n",
    "print(\"\\nMissing values in test dataset:\")\n",
    "print(missing_test[missing_test > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Are all the categories classified as bools? ###\n",
    "print(f\"Unique values in each category for train data:\")\n",
    "for col in LABELS:\n",
    "    if col in df_train.columns:\n",
    "        print(f\"\\t- {col}: {df_train[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd336c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Are all the comments in English? ###\n",
    "# Add a new columnn to the train dataset with the language of each comment\n",
    "df_train['language'] = df_train['comment_text'].progress_apply(detect_language)\n",
    "df_test['language'] = df_test['comment_text'].progress_apply(detect_language)\n",
    "\n",
    "# Show distribution of detected languages\n",
    "language_counts_train = df_train['language'].value_counts(normalize=True)\n",
    "language_counts_test = df_test['language'].value_counts(normalize=True)\n",
    "print(f\"Language distribution: {language_counts_train.to_dict()}\")\n",
    "print(f\"Language distribution in test set: {language_counts_test.to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual exploration of non-English comments\n",
    "df_train.loc[df_train['language'] != 'en'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
